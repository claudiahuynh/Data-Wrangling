---
title: "p8105_mh4589_hw2"
author: "My An Huynh"
date: "2024-09-25"
output: github_document
---

```{r echo = FALSE, message = FALSE}
library(tidyverse)
library(readxl)
```

Import the `subway` dataset

```{r subway}
subway_df = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", "", ".")) |>
  janitor::clean_names() |> 
  mutate( 
   entry = ifelse(is.na(entry), FALSE, TRUE)) |> 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) 

  

```

This dataset contains information on the NYC subway system. It includes division, line, station names within each line, and the routes each line serves. It also includes information on vending, staffing and accessibility (whether the station is ADA compliant, and entrance types). It also includes geographical information such as north-south streets, east-west streets, corner(NW, SW, etc), station location, longitude and latitude as well as entry location, longitude and latitude. 

I retained these following variables: line, station name, station latitude, station longitude, routes served, entry, vending, entrance type and ADA compliance.  The resulting data set contains `r ncol(subway_df)` columns and `r nrow(subway_df)` rows. 

The data is still not very tidy. 

There are `r nrow(subway_df |> distinct(line, station_name))` distinct stations by line and by name. There are a total of `r subway_df |>  summarise(count = sum(ada)) |>  pull(count)` stations that are ADA compliant. There are `r subway_df |> filter(entry =="TRUE", vending == "NO") |> summarise(count = n())` stations out of `r nrow(subway_df)` stations that allow entry without vending.



#Problem 2
Import `mr_trash` dataset. 
```{r mr_trash}
mr_trash_df = 
  read_excel(
     "data/202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Mr. Trash Wheel",
    range = "A2:N586",
    na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  mutate(
    sports_balls = as.integer(sports_balls),
    year = as.numeric(year),
    trash_wheel = "mr_trash"
  ) |> 
  relocate(dumpster, trash_wheel)

```


Import `prof_trash` dataset. 

```{r prof_trash}
prof_trash_df = 
  read_excel(
     "data/202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Professor Trash Wheel",
    na = c("NA", "", "."),
    range = "A2:M108"
  ) |> 
  janitor::clean_names()  |> 
  mutate(
    trash_wheel = "prof_trash"
  ) 


```


Import `gwynnda` dataset. 

```{r gwynnda}
gwynnda_df = 
  read_excel(
     "data/202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Gwynnda Trash Wheel",
    na = c("NA", "", "."),
    range = "A2:L157"
  ) |> 
  janitor::clean_names() |> 
  mutate(
    trash_wheel = "gwynnda"
  )

```

Combine 3 datasets. 

```{r trash_wheel}
trash_wheel_df = 
  bind_rows(mr_trash_df, prof_trash_df, gwynnda_df) |> 
  janitor::clean_names() |> 
  relocate(dumpster, trash_wheel) |> 
  select(dumpster:homes_powered)
```


I combined the 3 datasets (Mr Trash Wheel, Professor Trash Wheel and Gwynnda) into one dataset named trash_wheel_df. There are a total of `r nrow(trash_wheel_df)` rows and `r ncol(trash_wheel_df)` columns. The combined dataset `trash_wheel_df` provides information on the weight in tons and volume in cubic yards of trash each trash wheel removes from the Inner Harbor in Baltimore from May 2016 to June 2023. The dataset also provides information on the different types of trash (e.g plastic bottles, cigarette buds, sports balls, etc) and the quantity for each type of trash that each trash wheel removes from May 2016 to June 2023. The `homes_powered` variable shows the number of houses powered for every ton of trash removed. 


## Problem 3 

Import `bakers` dataset.
```{r bakers}
bakers_df = 
  read_csv("data/bakers.csv", na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  na.omit(bakers_df) |> 
  separate(
    baker_name, into = c("baker", "baker_last_name"), sep = " "
  ) |> 
  arrange(series)

```

Import `bakes` dataset.
```{r bakes}
bakes_df = 
  read_csv("data/bakes.csv", na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  mutate(
    baker = str_replace_all(baker, '"Jo"', "Jo")
  )
  
```

Import `results` dataset.
```{r results}
results_df = 
  read_csv("data/results.csv", na = c("NA", "", "."), skip = 2) |> 
  janitor::clean_names() |> 
  arrange(series, baker) |> 
  na.omit(results_df) |> 
  mutate(
    baker = ifelse(row_number() == 57:64, "Jo", baker)
  )

```

Use anti_join to view discrepancies.
```{r missing_data}
missing_bakes_df = anti_join(bakers_df, bakes_df)
missing_results_df = anti_join(bakers_df, results_df)

```

Join the three datasets. 

```{r final_gbb_df}
results_and_bakes_df = 
  left_join(bakes_df, results_df, by = c("baker", "series", "episode"))

joined_gbb_df =
  left_join(results_and_bakes_df, bakers_df, by = c("baker", "series"))

```
 
```{r}
winners_df =
  results_df |> 
  filter(series <= 10, series >=5) |> 
  filter(result %in% c("WINNER", "STAR BAKER"))  |> 
  select(series, episode, baker)

winners_df |>
  pivot_wider(
    names_from = series,
    values_from = baker
  ) |> 
  knitr::kable()
  
```
 
