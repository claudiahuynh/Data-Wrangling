---
title: "p8105_mh4589_hw2"
author: "My An Huynh"
date: "2024-09-25"
output: github_document
---

```{r echo = FALSE, message = FALSE}
library(tidyverse)
library(readxl)
```

## Problem 1

Import the `subway` dataset

```{r subway}
subway_df = 
  read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", "", ".")) |>
  janitor::clean_names() |> 
  mutate( 
   entry = ifelse(is.na(entry), FALSE, TRUE)) |> 
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) 

```

This dataset contains information on the NYC subway system. It includes division, line, station names within each line, and the routes each line serves. It also includes information on vending, staffing and accessibility (whether the station is ADA compliant, and entrance types). It also includes geographical information such as north-south streets, east-west streets, corner(NW, SW, etc), station location, longitude and latitude as well as entry location, longitude and latitude. 

I retained these following variables: line, station name, station latitude, station longitude, routes served, entry, vending, entrance type and ADA compliance.  The resulting data set contains `r ncol(subway_df)` columns and `r nrow(subway_df)` rows. 

The data is still not very tidy. 

There are `r nrow(subway_df |> distinct(line, station_name))` distinct stations by line and by name. There are a total of `r subway_df |>  summarise(count = sum(ada)) |>  pull(count)` stations that are ADA compliant. There are `r subway_df |> filter(entry =="TRUE", vending == "NO") |> summarise(count = n())` stations out of `r nrow(subway_df)` stations that allow entry without vending.

```{r}
subway_df_reformatted =
  subway_df |> 
  mutate(
    route8 = as.character(route8),
    route9 = as.character(route9),
    route10 = as.character(route10),
    route11 = as.character(route11)
  ) |> 
  pivot_longer(
    cols = route1:route11,
    names_to = "route_number",
    values_to = "route_name",
    names_prefix = "route"
  ) |> 
  relocate(route_number, route_name) |> 
  arrange(route_number) 

subway_a_df = 
  subway_df_reformatted |> 
  filter(route_name == "A") |> 
  distinct(station_name,line, .keep_all = TRUE) 


```

There are `r subway_a_df |> summarise(count = n())` distinct stations that serve the A train. Out of these stations, there are `r subway_a_df |> filter(ada == "TRUE") |> summarise(count = n())` stations that are ADA compliant. 

## Problem 2

Import `mr_trash` dataset. 
```{r mr_trash}
mr_trash_df = 
  read_excel(
     "data/202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Mr. Trash Wheel",
    range = "A2:N586",
    na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  mutate(
    sports_balls = as.integer(sports_balls),
    year = as.numeric(year),
    trash_wheel = "mr_trash"
  ) |> 
  relocate(dumpster, trash_wheel)

```


Import `prof_trash` dataset. 

```{r prof_trash}
prof_trash_df = 
  read_excel(
     "data/202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Professor Trash Wheel",
    na = c("NA", "", "."),
    range = "A2:M108"
  ) |> 
  janitor::clean_names()  |> 
  mutate(
    trash_wheel = "prof_trash"
  ) 


```


Import `gwynnda` dataset. 

```{r gwynnda}
gwynnda_df = 
  read_excel(
     "data/202309 Trash Wheel Collection Data.xlsx", 
    sheet = "Gwynnda Trash Wheel",
    na = c("NA", "", "."),
    range = "A2:L157"
  ) |> 
  janitor::clean_names() |> 
  mutate(
    trash_wheel = "gwynnda"
  )

```

Combine 3 datasets. 

```{r trash_wheel}
trash_wheel_df = 
  bind_rows(mr_trash_df, prof_trash_df, gwynnda_df) |> 
  janitor::clean_names() |> 
  relocate(dumpster, trash_wheel) |> 
  select(dumpster:homes_powered)
```


I combined the 3 datasets (Mr Trash Wheel, Professor Trash Wheel and Gwynnda) into one dataset named trash_wheel_df. There are a total of `r nrow(trash_wheel_df)` rows and `r ncol(trash_wheel_df)` columns. The combined dataset `trash_wheel_df` provides information on the weight in tons and volume in cubic yards of trash each trash wheel removes from the Inner Harbor in Baltimore from May 2016 to June 2023. The dataset also provides information on the different types of trash (e.g plastic bottles, cigarette buds, sports balls, etc) and the quantity for each type of trash that each trash wheel removes from May 2016 to June 2023. The `homes_powered` variable shows the number of houses powered for every ton of trash removed. 

The total weight of trash collected by Professor Trash Wheel is `r prof_trash_df |> summarise(sum(weight_tons, na.rm = TRUE))` tons. The total number of cigarette butts collected by Gwynnda in June of 2022 is `r gwynnda_df |> filter(month == "June", year =="2022") |> summarise(sum(cigarette_butts, na.rm = TRUE))` butts.


## Problem 3 

Import `bakers` dataset.
```{r bakers}
bakers_df = 
  read_csv("data/bakers.csv", na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  na.omit(bakers_df) |> 
  separate(
    baker_name, into = c("baker", "baker_last_name"), sep = " "
  ) |> 
  arrange(series)

```

Import `bakes` dataset.
```{r bakes}
bakes_df = 
  read_csv("data/bakes.csv", na = c("NA", "", ".")) |> 
  janitor::clean_names() |> 
  mutate(
    baker = str_replace_all(baker, '"Jo"', "Jo")
  )
  
```

Import `results` dataset.
```{r results}
results_df = 
  read_csv("data/results.csv", na = c("NA", "", "."), skip = 2) |> 
  janitor::clean_names() |> 
  arrange(series, baker) |> 
  na.omit(results_df) |> 
  mutate(
    baker = ifelse(row_number() == 57:64, "Jo", baker)
  )

```

Use anti_join to view discrepancies.
```{r missing_data}
missing_bakes_df = anti_join(bakers_df, bakes_df)
missing_results_df = anti_join(bakers_df, results_df)

```

Join the three datasets. 

```{r final_gbb_df}
results_and_bakes_df = 
  left_join(bakes_df, results_df, by = c("baker", "series", "episode"))

joined_gbb_df =
  left_join(results_and_bakes_df, bakers_df, by = c("baker", "series"))

```

I imported the three datasets: `bakers`, `bakes` and `results` and cleaned variable names. For the `bakers` dataset, I separated the baker's full names to two columns - first and last name. For the `bakes` dataset, I used str_replace_all to get rid of the quotation marks around "Jo". I replaced Joanne with Jo in the `results` dataset for consistency. I noticed these discrepancies by using `anti_join()`. The results from using `anti_join()` also show that the `bakes` dataset only show information from series 1 to 8. 

I used `left_join` to merge all 3 datasets into a single dataset named `joined_gbb_df`. The dataset includes information on the bakers' background (age, hometown, etc), signature bakes, show stoppers, and their results (whether they move forward or get eliminated). Because the `bakes` dataset is incomplete, the joined dataset also only includes information up to series 8. 

```{r}
winners_df =
  results_df |> 
  filter(series <= 10, series >=5) |> 
  filter(result %in% c("WINNER", "STAR BAKER"))  |> 
  select(series, episode, baker, result)

winners_df |>
  pivot_wider(
    names_from = series,
    values_from = baker
  ) |> 
  arrange(episode) |> 
  knitr::kable()
  
```
 
 I created a reader-friendly table that extracts information from the `results` dataset and includes information on the star bakers and winners across seasons 5 to 10. I noticed some predictability in that the winners in series 5 to 9 won "star baker" at least once. The only exception is the winner in series 10, David, who had never won star baker. 
 
Import the `views` dataset

```{r}
viewership_df = 
  read_csv("data/viewers.csv") |> 
  janitor::clean_names() |> 
  na.omit(views_df) |> 
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewership",
    names_prefix = "series_"
  ) |> 
  mutate(
    series = as.numeric(series)
  ) |> 
  arrange(series) |> 
  relocate(series)

knitr::kable(head(viewership_df, 10), caption = "First 10 rows in the Viewership dataset")
```

The average viewership in series 1 is `r viewership_df |> filter(series == "1") |> summarise(mean(viewership, na.rm = TRUE))`. The average viewership in series 5 is `r viewership_df |> filter(series == "5") |> summarise(mean(viewership, na.rm = TRUE))`.
